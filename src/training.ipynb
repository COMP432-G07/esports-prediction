{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.dummy\n",
    "import sklearn.metrics\n",
    "import sklearn.neural_network\n",
    "import sklearn.ensemble\n",
    "from joblib import dump\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the data frames from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read both the matches and the frames\n",
    "trn_df = pd.read_csv('../data/processed/diff_trn.csv').drop(labels=['tier','Unnamed: 0'],axis=1)\n",
    "tst_df = pd.read_csv('../data/processed/diff_tst.csv').drop(labels=['tier','Unnamed: 0'],axis=1)\n",
    "# Reinterpret all values as int32s\n",
    "trn_df = trn_df.astype({\n",
    "    'winner': 'int32',\n",
    "    'first_kill': 'int32',\n",
    "    'first_tower': 'int32',\n",
    "    'first_inhibitor': 'int32',\n",
    "    'first_baron': 'int32',\n",
    "    'first_dragon': 'int32',\n",
    "    'first_rift_herald': 'int32',\n",
    "})\n",
    "\n",
    "tst_df = tst_df.astype({\n",
    "    'winner': 'int32',\n",
    "    'first_kill': 'int32',\n",
    "    'first_tower': 'int32',\n",
    "    'first_inhibitor': 'int32',\n",
    "    'first_baron': 'int32',\n",
    "    'first_dragon': 'int32',\n",
    "    'first_rift_herald': 'int32',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to format the data prior to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "np.random.seed(random_state)\n",
    "dpi = 300\n",
    "\n",
    "def corr_filter(n):\n",
    "    \"\"\" Filters the set of features based on minimum correlation n\"\"\"\n",
    "    all_features = list(tuple(zip(trn_df.corr()['winner'].drop(['winner']).index.to_list(),\n",
    "          trn_df.corr()['winner'].drop(['winner']).to_list())))\n",
    "    drop = [i[0] for i in all_features if i[1] < n]\n",
    "    trn_df.drop(columns=drop, inplace=True)\n",
    "    tst_df.drop(columns=drop, inplace=True)\n",
    "    \n",
    "def plot_data(X, y):\n",
    "    return\n",
    "    \"\"\"Plots the data.\"\"\"\n",
    "    plt.scatter(*X[y==-1].T, marker=\"x\", c=\"r\")\n",
    "    plt.scatter(*X[y==1].T, marker=\"x\", c=\"b\")\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.grid(False)\n",
    "\n",
    "def plot_decision_function(model):\n",
    "    return\n",
    "    \"\"\"\n",
    "    Plots the decision function of a model as a red-blue heatmap.\n",
    "    The region evaluated, along with x and y axis limits, are determined by 'extent'.\n",
    "    \"\"\"\n",
    "    extent = (0 , 1, 0, 1)\n",
    "    x1min, x1max ,x2min, x2max = extent\n",
    "    x1, x2 = np.meshgrid(np.linspace(x1min, x1max, 200), np.linspace(x2min, x2max, 200))\n",
    "    X = np.column_stack([x1.ravel(), x2.ravel()])\n",
    "    y = model.decision_function(X).reshape(x1.shape)\n",
    "    plt.imshow(-y, extent=extent, origin='lower', vmin=-1, vmax=1, cmap='bwr', alpha=0.5, interpolation='nearest')\n",
    "    if y.min() < 0 and y.max() > 0:\n",
    "        plt.contour(x1, x2, y, levels=[0], colors=['k'])  # Decision boundary\n",
    "    plt.xlim([x1min, x1max])\n",
    "    plt.ylim([x2min, x2max])\n",
    "    plt.grid(False)\n",
    "    \n",
    "def plot_rf_prediction(model):\n",
    "    \"\"\"\n",
    "    Plots the model's predictions over all points in range 2D [-3, 3].\n",
    "    Assumes at most 3 classes.\n",
    "    \"\"\"\n",
    "    return\n",
    "    extent = (0, 1, 0, 1)\n",
    "    x1min, x1max ,x2min, x2max = extent\n",
    "    x1, x2 = np.meshgrid(np.linspace(x1min, x1max, 100), np.linspace(x2min, x2max, 100))\n",
    "    X = np.column_stack([x1.ravel(), x2.ravel()])\n",
    "    y = model.predict(X).reshape(x1.shape)\n",
    "    cmap = matplotlib.colors.ListedColormap(['r', 'b', 'g'])\n",
    "    plt.imshow(y, extent=extent, origin='lower', alpha=0.4, vmin=0, vmax=2, cmap=cmap, interpolation='nearest')\n",
    "    plt.xlim([x1min, x1max])\n",
    "    plt.ylim([x2min, x2max])\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.grid(False)\n",
    "\n",
    "def scale_data(X_trn, X_tst):\n",
    "    \"\"\"\n",
    "    Scales the data with Scikit-learn's MinMax scaler.\n",
    "    \"\"\"\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    scaler.fit(X_trn)\n",
    "    X_trn = scaler.transform(X_trn)\n",
    "    X_tst = scaler.transform(X_tst)\n",
    "\n",
    "    return X_trn, X_tst\n",
    "\n",
    "def score_estimators(X, y, estimators):\n",
    "    \"\"\"\n",
    "    Scores each estimator on (X, y), returning a list of scores.\n",
    "    \"\"\"\n",
    "    scores = [0 for _ in range(len(estimators))]\n",
    "    for x in range(len(estimators)):\n",
    "        scores[x] = sklearn.metrics.accuracy_score(y, estimators[x].predict(X))\n",
    "        print(sklearn.metrics.precision_recall_fscore_support(y, estimators[x].predict(X), average='binary'))\n",
    "    return scores\n",
    "\n",
    "def plot_estimator_scores(estimators, param_name, param_vals):\n",
    "    \"\"\"\n",
    "    Plots the training, validation, and testing scores of a list of estimators,\n",
    "    where `param_name` and `param_vals` are the same as for `train_estimators`.\n",
    "    The estimator with best validation score will be highlighted with an 'x'.\n",
    "    \"\"\"\n",
    "    plt.figure(dpi=dpi)\n",
    "    X = np.arange(0, len(param_vals))\n",
    "    trn_scores = score_estimators(X_trn, y_trn, estimators)\n",
    "    tst_scores = score_estimators(X_tst, y_tst, estimators)\n",
    "    index = np.argmin(trn_scores - tst_scores)\n",
    "    print(tst_scores[index])\n",
    "    plt.title(estimators[0].__class__.__name__ + \" score vs \" + param_name)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.ylim(0.0, 1.05)\n",
    "    plt.scatter(X[index], tst_scores[index], marker='x', color='black', s=200)\n",
    "    plt.plot(X, trn_scores, marker='o', color='green', markerfacecolor='green', label=\"train\")\n",
    "    plt.plot(X, tst_scores, marker='o', color='red', markerfacecolor='red', label=\"test\")\n",
    "    plt.text(0, 0.4,\n",
    "             \"Optimal Test Accuracy = %.2f%% with %s = %d \" % (tst_scores[index] * 100, param_name, param_vals[index]))\n",
    "    plt.legend()\n",
    "    plt.xticks(X, param_vals)\n",
    "    plt.grid(False)\n",
    "    \n",
    "\n",
    "def rand_param_search(X, y, estimator, param_grid, verbose=1, cv=5, n_iter=10, n_jobs=None):\n",
    "    return sklearn.model_selection.RandomizedSearchCV(estimator, param_grid,verbose=verbose,\n",
    "                                        cv=cv, n_iter=n_iter, n_jobs=n_jobs).fit(X, y)\n",
    "\n",
    "def grid_param_search(X, y, estimator, param_grid, verbose=1, cv=5, n_jobs=None):\n",
    "    return sklearn.model_selection.GridSearchCV(estimator, param_grid, verbose=verbose,\n",
    "                                        cv=cv, n_jobs=n_jobs).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection: Select an X and y we want to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select data points for plots\n",
    "corr_filter(0.5)\n",
    "indices = np.random.choice(trn_df.shape[0], 200, replace=False)\n",
    "X_trn = trn_df.drop(columns=['winner']).values\n",
    "y_trn = trn_df[['winner']].values.T[0]\n",
    "X_tst = tst_df.drop(columns=['winner']).values\n",
    "y_tst = tst_df[['winner']].values.T[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scales the data with Scikit-learn's MinMax scaler.\n",
    "\"\"\"\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_trn)\n",
    "X_trn = scaler.transform(X_trn)\n",
    "X_tst = scaler.transform(X_tst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "ab = sklearn.ensemble.AdaBoostClassifier(random_state=random_state)\n",
    "param_grid = {\n",
    "    'n_estimators' : [i for i in scipy.stats.uniform(1, 1000).rvs(10).astype('int32')],\n",
    "    'algorithm' : ['SAMME', 'SAMME.R'] \n",
    "}\n",
    "ab = rand_param_search(X_trn, y_trn, ab, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_trn[indices], y_trn[indices])\n",
    "plot_rf_prediction(ab.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "lr = sklearn.linear_model.LogisticRegression(random_state=random_state, max_iter=10000)\n",
    "param_grid = {\n",
    "    'C': [i for i in scipy.stats.reciprocal(1e-05, 10).rvs(10)]\n",
    "}\n",
    "lr = rand_param_search(X_trn, y_trn, lr, param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_trn[indices], y_trn[indices])\n",
    "plot_rf_prediction(lr.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "svm = sklearn.svm.SVC(random_state=random_state)\n",
    "param_grid = {\n",
    "    'C': [i for i in scipy.stats.reciprocal(0.01, 1000).rvs(10)],\n",
    "    'gamma' : [i for i in scipy.stats.reciprocal(1, 1000).rvs(10)]\n",
    "}\n",
    "svm = rand_param_search(X_trn, y_trn, svm, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_trn[indices], y_trn[indices])\n",
    "plot_rf_prediction(svm.best_estimator_)\n",
    "plot_decision_function(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=0, strategy='uniform')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = sklearn.dummy.DummyClassifier(strategy='uniform', random_state=0)\n",
    "dummy.fit(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_trn[indices], y_trn[indices])\n",
    "plot_rf_prediction(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [1, 5, 10, 15, 20]\n",
    "}\n",
    "knn = sklearn.neighbors.KNeighborsClassifier()\n",
    "knn = grid_param_search(X_trn, y_trn, estimator=knn, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_trn[indices], y_trn[indices])\n",
    "plot_rf_prediction(knn.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(1, 5) * 50, \n",
    "    'max_depth': np.arange(1, 5) * 5\n",
    "}\n",
    "rf = sklearn.ensemble.RandomForestClassifier(random_state=0)\n",
    "rf = grid_param_search(X_trn, y_trn, estimator=rf, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_trn[indices], y_trn[indices])\n",
    "plot_rf_prediction(rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/b_lofo/.pyenv/versions/3.9.7/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "net = sklearn.neural_network.MLPClassifier(        \n",
    "    learning_rate_init=0.01,\n",
    "    activation='logistic',\n",
    "    hidden_layer_sizes=(2,),\n",
    "    momentum=0.9,\n",
    "    solver='sgd',\n",
    "    random_state=0,\n",
    ")\n",
    "param_grid = [\n",
    "    {\n",
    "        'max_iter': [5, 10, 50, 100, 150, 200]\n",
    "    }\n",
    "]\n",
    "net = grid_param_search(X_trn, y_trn, estimator=net, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_trn[indices], y_trn[indices])\n",
    "plot_rf_prediction(net.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting each prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13af74a00>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(net.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Scores from best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for KNeighborsClassifier:\n",
      "Accuracy: 0.9035714285714286\n",
      "Precision: 0.8961364776718515\n",
      "Recall: 0.912621359223301\n",
      "Scores for RandomForestClassifier:\n",
      "Accuracy: 0.9048469387755103\n",
      "Precision: 0.8971915747241725\n",
      "Recall: 0.9141543178334185\n",
      "Scores for AdaBoostClassifier:\n",
      "Accuracy: 0.9012755102040816\n",
      "Precision: 0.8940763052208835\n",
      "Recall: 0.9100664282064385\n",
      "Scores for LogisticRegression:\n",
      "Accuracy: 0.9028061224489796\n",
      "Precision: 0.8987854251012146\n",
      "Recall: 0.9075114971895759\n",
      "Scores for SVC:\n",
      "Accuracy: 0.9040816326530612\n",
      "Precision: 0.8970366649924661\n",
      "Recall: 0.912621359223301\n",
      "Scores for MLPClassifier:\n",
      "Accuracy: 0.9022959183673469\n",
      "Precision: 0.8935\n",
      "Recall: 0.9131323454266734\n"
     ]
    }
   ],
   "source": [
    "for estimator in [knn, rf, ab, lr, svm, net]:\n",
    "    y_pred = estimator.predict(X_tst)\n",
    "    stats = sklearn.metrics.precision_recall_fscore_support(y_tst, y_pred, average='binary')\n",
    "    print(\"Scores for %s:\" % estimator.best_estimator_.__class__.__name__)\n",
    "    print(\"Accuracy: %s\" % sklearn.metrics.accuracy_score(y_tst, y_pred))\n",
    "    print(\"Precision: %s\" % stats[0])\n",
    "    print(\"Recall: %s\" % stats[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_inhibitor</th>\n",
       "      <th>first_baron</th>\n",
       "      <th>kill_advantage</th>\n",
       "      <th>gold_advantage</th>\n",
       "      <th>damage_advantage</th>\n",
       "      <th>tower_advantage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2391.0</td>\n",
       "      <td>-15982.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1637.0</td>\n",
       "      <td>-3938.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5682.0</td>\n",
       "      <td>15075.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-1472.0</td>\n",
       "      <td>-12730.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5792.0</td>\n",
       "      <td>-16715.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1331.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1545.0</td>\n",
       "      <td>-1523.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-3439.0</td>\n",
       "      <td>-4507.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_inhibitor  first_baron  kill_advantage  gold_advantage  \\\n",
       "0             -1.0          1.0             4.0         -2391.0   \n",
       "1             -1.0          1.0             6.0         -1637.0   \n",
       "2             -1.0         -1.0             7.0          5682.0   \n",
       "3             -1.0          1.0             5.0          1811.0   \n",
       "4             -1.0         -1.0           -15.0         -1472.0   \n",
       "5             -1.0          1.0             0.0         -5792.0   \n",
       "6             -1.0         -1.0             6.0         -1331.0   \n",
       "7             -1.0         -1.0             5.0         -1545.0   \n",
       "8             -1.0         -1.0            -7.0         -3439.0   \n",
       "9             -1.0         -1.0             3.0          1807.0   \n",
       "\n",
       "   damage_advantage  tower_advantage  \n",
       "0          -15982.0             -5.0  \n",
       "1           -3938.0             -1.0  \n",
       "2           15075.0              3.0  \n",
       "3           13800.0              1.0  \n",
       "4          -12730.0             -4.0  \n",
       "5          -16715.0             -2.0  \n",
       "6            1437.0              0.0  \n",
       "7           -1523.0             -3.0  \n",
       "8           -4507.0             -4.0  \n",
       "9             466.0              3.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "misclassified, = np.nonzero(np.logical_and(y_tst==1, y_pred==-1))\n",
    "pd.DataFrame(data=scaler.inverse_transform(X_tst[misclassified]), columns=trn_df.drop(columns=['winner']).columns).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_clf.joblib']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump each models for the TAs to try them out\n",
    "dump(dummy, 'dm_clf.joblib')\n",
    "dump(lr.best_estimator_, 'logistic_clf.joblib')\n",
    "dump(ab.best_estimator_, 'boost_clf.joblib')\n",
    "dump(svm.best_estimator_, 'svm_clf.joblib')\n",
    "dump(net.best_estimator_, 'nn_clf.joblib')\n",
    "dump(knn.best_estimator_, 'knn_clf.joblib')\n",
    "dump(rf.best_estimator_, 'rf_clf.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
